{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "# from langchain.chains import LLMChain\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain_community.llms import GPT4All\n",
    "\n",
    "# local_path = (\n",
    "#     \"./models/ggml-gpt4all-l13b-snoozy.bin\"  # replace with your desired local file path\n",
    "# )\n",
    "\n",
    "# # Callbacks support token-wise streaming\n",
    "# callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "# # Verbose is required to pass to the callback manager\n",
    "# # llm = GPT4All(model=\"/Users/omdeshmukh/Downloads/SemVI/proj/gpt4all-falcon-newbpe-q4_0.gguf\", callbacks=callbacks, verbose=True)\n",
    "\n",
    "# # template = \"\"\"Question: {question}\n",
    "\n",
    "# # Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "# # prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "# # llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# # question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
    "\n",
    "# # llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "\n",
    "api_key = 'AIzaSyDiHpKmF-21h_ioShSBD2WB6E-4dcezZjg'\n",
    "\n",
    "llm = GooglePalm(google_api_key=api_key, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from transformers import pipeline\n",
    "\n",
    "# model_id = \"gpt2\"  # Specify the desired GPT-2 model variant (e.g., \"gpt2-medium\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100)  # Adjust max_new_tokens as needed\n",
    "# hf = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# # from langchain.prompts import PromptTemplate\n",
    "\n",
    "# # template = \"\"\"Question: {question} Answer: Let's think step by step.\"\"\"\n",
    "# # prompt = PromptTemplate.from_template(template)\n",
    "# # chain = prompt | hf  # Combine prompt and GPT-2 pipeline\n",
    "\n",
    "# # question = \"What is an llm?\"\n",
    "# # print(chain.invoke({\"question\": question}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for databases\n",
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "db_user = \"root\"\n",
    "db_password = \"sql#pass\"\n",
    "db_host = \"localhost\"\n",
    "db_name = \"atliq_tshirts\"\n",
    "\n",
    "db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\",sample_rows_in_table_info=3)\n",
    "# print(db.table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How many t-shirts do we have left for nike in extra small size and white color?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT stock_quantity FROM t_shirts WHERE brand = 'Nike' AND color = 'White' AND size = 'XS'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(58,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m58\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How much is the price of the inventory for all small size t-shirts?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT SUM(price) FROM t_shirts WHERE size = 'S'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('263'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m263\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "SELECT SUM(price*stock_quantity) FROM t_shirts WHERE size = 'S'\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT SUM(price*stock_quantity) FROM t_shirts WHERE size = 'S'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('19785'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m19785\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('28305'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m28305\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('277'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m277\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose = True)\n",
    "qns1 = db_chain.run(\"How many t-shirts do we have left for nike in extra small size and white color?\")\n",
    "qns2 = db_chain.run(\"How much is the price of the inventory for all small size t-shirts?\")\n",
    "qns3 = db_chain.run(\"SELECT SUM(price*stock_quantity) FROM t_shirts WHERE size = 'S'\")\n",
    "qns4 = db_chain.run(\"SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\")\n",
    "qns5 = db_chain.run(\"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for few shot learning\n",
    "few_shots = [\n",
    "    {'Question' : \"How many t-shirts do we have left for Nike in XS size and white color?\",\n",
    "     'SQLQuery' : \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Nike' AND color = 'White' AND size = 'XS'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer' : qns1\n",
    "     },\n",
    "    {'Question': \"How much is the total price of the inventory for all S-size t-shirts?\",\n",
    "     'SQLQuery':\"SELECT SUM(price*stock_quantity) FROM t_shirts WHERE size = 'S'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': qns2\n",
    "     },\n",
    "    {'Question': \"If we have to sell all the Levi’s T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?\" ,\n",
    "     'SQLQuery' : \"\"\"SELECT sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
    "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Levi'\n",
    "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\n",
    " \"\"\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': qns3\n",
    "     } ,\n",
    "     {'Question' : \"If we have to sell all the Levi’s T-shirts today. How much revenue our store will generate without discount?\" ,\n",
    "      'SQLQuery': \"SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\",\n",
    "      'SQLResult': \"Result of the SQL query\",\n",
    "      'Answer' : qns4\n",
    "      },\n",
    "    {'Question': \"How many white color Levi's shirt I have?\",\n",
    "     'SQLQuery' : \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer' : qns5\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for converting to word embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# creating a l=blob for our vector database\n",
    "to_vectorise = [\" \".join(temp.values()) for temp in few_shots]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['How many t-shirts do we have left for Nike in XS size and white color?', \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Nike' AND color = 'White' AND size = 'XS'\", 'Result of the SQL query', '58'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a vector database\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vector_db = Chroma.from_texts(to_vectorise, embeddings, metadatas=few_shots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
